---
layout: project
urltitle:  "Automated Reinforcement Learning (AutoRL)"
title: "Automated Reinforcement Learning (AutoRL)"
categories: workshop, icml, autorl, reinforcement learning, automl, 2024
permalink: /
bibtex: true
paper: true
acknowledgements: ""
---
<br/>

<div class="row reverse">
  <div class="col-xs-12 col-md-7">
    <h1>Automated Reinforcement Learning: Exploring Meta-Learning, AutoML, and LLMs </h1>
    <br>
    <h4>July, 2024 // ICML Workshop</h4>
    <br>
    <br>
    <p>
      The past few years has seen a surge of interest in reinforcement learning, , with breakthrough successes of applying RL in games, robotics, chemistry, logistics, nuclear fusion and more.
      These headlines, however, blur the picture of what remains a brittle technology, with many successes relying on heavily engineered solutions.
      Indeed, several recent works have demonstrated that RL algorithms are brittle to seemingly mundane design choices . Thus, it is often a significant challenge to effectively apply RL in practice, especially on novel problems, limiting its potential impact and narrowing its accessibility. 
    </p>
    <p>
      In this workshop, we want to bring together different communities working on solving these problems. 
      A variety of distinct sub-communities spanning RL, Meta-Learning and AutoML have been working on making RL work <b>out-of-the-box</b> in arbitrary settings - this is the AutoRL setting. Recently, with the emergence of LLMs and their in-context learning abilities, they have significantly impacted all these communities. There are LLM agents tackling traditional RL tasks as well as few-shot RL agents increasing efficiency and generalization that are also trying to automate RL. LLMs have also been influencing AutoML directly with papers such as OptFormer . However, there is currently little crossover between these communities. As such, we want to create the space to connect them and cross-pollinate ideas automating RL. 
      We believe closer connections between these communities will ultimately lead to faster and more focused progress on AutoRL and an in-person workshop is the ideal way to allow for greater interaction between them.
      Through a mixture of diverse expert talks and opportunity for conversation, we hope to emphasize the many facets of current AutoRL approaches and where collaboration across fields is possible. 
    </p>
    <p>
    <p style="color:#c31;"><b>Update:</b></p> <b>The workshop has been accepted at ICML 2024 to be held in Vienna. Location: Stolz 0, Messe Wien Exhibition Congress Center. Date: 27 July 2024</b>. 
       </p>
    <p>
    Contact: <a href="mailto:autorlworkshop@ai.uni-hannover.de">autorlworkshop@ai.uni-hannover.de</a>
       </p>
    <p>
    <a href="https://app.sli.do/event/5f3vjJ61fpXpa8eBE49QUu">Ask questions for the panel discussion</a>
       </p>
  </div>
  <div class="col-md-1 hidden-xs">
  </div>
  <div class="col-xs-12 col-md-4">
    <img class="cover" src="/static/img/cover.png">
  </div>
</div>

<br/>

<div class="row">
    <div class="col-xs-8">
    <img src="/static/img/people/AutoRL_workshop_slido_qr_code.png">
    </div>
    <div class="col-xs-8">
    <img src="/static/img/fig_2_survey.png">
    </div>
</div>

<br/>

<div class="row">
    <div class="col-xs-8">
        
    </div>

</div>

<div class="row" id="accepted">
  <div class="col-xs-12">
    <h2>Accepted papers</h2>
    Accepted papers can be found <a href="https://openreview.net/group?id=ICML.cc/2024/Workshop/AutoRL&referrer=%5BHomepage%5D(%2F)#tab-accept">here</a>. Camera-ready versions of all the papers will soon be available on <a href="https://openreview.net/group?id=ICML.cc/2024/Workshop/AutoRL">OpenReview</a>. We also want to highlight three excellent Spotlight Papers:
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <h4><a href="https://openreview.net/forum?id=623QP3J4SK">Can Learned Optimization Make Reinforcement Learning Less Difficult?</a></h4>
    Alexander D. Goldie, Chris Lu, Matthew Thomas Jackson, Shimon Whiteson, Jakob Nicolaus Foerster
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <h4><a href="https://openreview.net/forum?id=ShXsJ1EGWK">BOFormer: Learning to Solve Multi-Objective Bayesian Optimization via Non-Markovian RL</a></h4>
    Yu Heng Hung, Kai-Jie Lin, Yu-Heng Lin, Chien-Yi Wang, Ping-Chun Hsieh
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <h4><a href="https://openreview.net/forum?id=W4vHmhn0xd">Self-Exploring Language Models: Active Preference Elicitation for Online Alignment</a></h4>
    Shenao Zhang, Donghan Yu, Hiteshi Sharma, Ziyi Yang, Shuohang Wang, Hany Hassan Awadalla, Zhaoran Wang
  </div>
</div>

<div class="row" id="schedule">
  <div class="col-xs-12">
    <h2>Official schedule</h2>
    <br/>
    <p> All times listed below are in Central European Summer Time (CEST).  </p> 
<!--     <p>Other important links:</p> -->
     <ul>
<!--               <li><b>GatherTown</b>: <a href="https:/icml.cc">Link</a></li> -->
<!--               <li><b>Zoom</b>: <a href="https://icml.cc/">Link TBA</a></li> -->
    </ul>
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
<!--        <tr>
          <td>8:30 - 9:00 AM</td>
          <td>
            Coffee
          </td>
        </tr>-->
        <tr>
          <td>9:00 - 9:30 AM</td>
          <td>
            Invited talk 1: tba <br/>
            <i> Chelsea Finn </i>
          </td>
        </tr>
        <tr>
          <td>9:30 - 9:45 AM</td>
          <td>
            Contributed talk 1: Self-Exploring Language Models: Active Preference Elicitation for Online Alignment <br/>
            <i> Shenao Zhang </i>
          </td>
        </tr>
        <tr>
          <td>9:45 - 10:00 AM</td>
          <td>
            Contributed talk 2: BOFormer: Learning to Solve Multi-Objective Bayesian Optimization via Non-Markovian RL<br/>
            <i> Yu-Heng Hung and Ping-Chun Hsieh </i>
          </td>
        </tr>
        <tr>
          <td>10:00 - 11:00 AM</td>
          <td>
            Poster Session
          </td>
        </tr>
        <tr>
          <td>11:00 - 11:30 AM</td>
          <td>
            Invited Talk 2: Learning to Solve New sequential decision-making Tasks with In-Context Learning + work on generalization in offline RL<br/>
            <i> Roberta Raileanu </i>
          </td>
        </tr>
        <tr>
          <td>11:30 - 12:00 PM</td>
          <td>
            Invited Talk 3: AI-Assisted Agent Design with Large Language Models and Reinforcement Learning<br/>
            <i> Pierluca D'Oro </i>
          </td>
        </tr>
        <tr>
          <td>12:00 - 12:30 PM</td>
          <td>
            Breakout Session <br/>
            <i> X </i>
          </td>
        </tr>
        <tr>
          <td>12:30 - 2:00 PM</td>
          <td>
            Lunch Break
          </td>
        </tr>
        <tr>
          <td>2:00 - 2:30 PM</td>
          <td>
            Invited talk 4:<br/>
            <i> Michael Dennis </i>
          </td>
        </tr>
        <tr>
          <td>2:30 - 2:45 PM</td>
          <td>
            Contributed Talk 3: Can Learned Optimization Make Reinforcement Learning Less Difficult?<br/>
            <i> Alexander D. Goldie </i>
          </td>
        </tr>
        <tr>
          <td>2:45 - 3:15 PM</td>
          <td>
            Invited talk 5: In defense of Atari: The ALE as a benchmark for AutoRL<br>
            <i> Pablo Samuel Castro </i>
          </td>
        </tr>
        <tr>
          <td>3:30 - 4:00 PM</td>
          <td>
            Coffee Break <br/>
          </td>
        </tr>
        <tr>
          <td>4:00 - 5:00 PM</td>
          <td> Panel Discussion & Closing Remarks<br>
            <i> Pablo Samuel Castro, Jacob Beck, Doina Precup, Alexander D. Goldie.</i> 
            </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>


<div class="row" id="dates">
  <div class="col-xs-12">
    <h2>Important Dates (currently all provisional)</h2>
  </div>
</div>

<br>
<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>Paper Submission Deadline</td> <!-- Neurips Main Conference Full Paper Submission Deadline	May 22 '24 08:00 PM UTC            -->
          <td>31.05.2024 AOE</td>
        </tr>
        <tr>
          <td>Decision Notifications</td>
          <td>17.06.2024</td>
        </tr>
        <tr>
<!--          <td>Deadline for complimentary registration applications</td>
          <td>10.03.2024</td>-->
        </tr>
        <tr>
          <td>Camera Ready Paper Deadline </td> <!--         & complimentary registration notifications -->
          <td>1.07.2024</td>
        </tr>
        <tr>
          <td>Paper Video Submission Deadline</td>
          <td>8.07.2024</td>
        </tr>
        <tr>
          <td>Workshop</td>
          <td>27.07.2024</td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<br />

<div class="row" id="cfp">
  <div class="col-xs-12">
  
  <h2>Call for Papers</h2>

<p>We invite <strong>both short</strong> (4 page) <strong>and long</strong> (9 page) anonymized submissions that develop algorithms, benchmarks, and ideas to allow reinforcement learning agents to learn more effectively out of the box. Submissions should be in the <a href="https://media.neurips.cc/Conferences/NeurIPS2024/Styles.zip">NeurIPS LaTeX format</a>. We also welcome review and positional papers that may foster discussions. Note that as per ICML guidelines, we don't accept works previously published in other conferences on machine learning, but are open to works that are currently under submission to a conference.</p>

<p>The workshop will focus on novel and unpublished work including, but not limited to, the areas of:</p>

<div style="column-count: 2;">
<ul style="list-style-type: disc; padding-left: 20px;">
    <li>LLMs for reinforcement learning</li>
    <li>In-context reinforcement learning</li>
    <li>Meta-reinforcement learning</li>
    <li>RL algorithm discovery</li>
    <li>Fairness &amp; interpretability via AutoRL</li>
    <li>Curricula and open-endedness in RL</li>
    <li>AutoML for reinforcement learning</li>
    <li>Reinforcement learning for LLMs</li>
    <li>NAS for deep reinforcement learning</li>
    <li>Theoretical guarantees for AutoRL</li>
    <li>Feature- &amp; Hyperparameter importance for RL algorithms</li>
    <li>Demos of AutoRL systems</li>
    <li>Hyperparameter agnostic RL algorithms</li>
</ul>
</div>

<p>Papers should not exceed 9 pages in length, excluding references and appendices. All of these should be submitted in a <strong>single file</strong> via <a href="https://openreview.net/group?id=ICML.cc/2024/Workshop/AutoRL">OpenReview</a>. The review process will be <strong>double blind</strong>. We will <strong>not have archival proceedings</strong>, but will share accepted papers on the workshop website. We encourage including code in papers, though we ask to anonymize the code along with the submission. Any paper that includes code will receive a <em>code badge</em> on the workshop website. We require a short summary video of at most 5 minutes for accepted papers. These will be uploaded to YouTube.</p>

<p>If you are interested in reviewing for the workshop, please get in touch through <a href="https://forms.gle/w9keqWw5gkkoomWA9">this Google form</a>.</p>

<h2>Key Dates</h2>
<ul>
    <li><strong>Paper submission deadline:</strong> 31.05.2024 AOE</li>
    <li><strong>Decision notifications by:</strong> 17.06.2024</li>
    <li><strong>Camera ready version due:</strong> 01.07.2024</li>
    <li><strong>Video deadline:</strong> 08.07.2024</li>
</ul>

<!--    <h2>Call for Papers</h2>
  </div>
</div>


<div class="row">
  <div class="col-xs-12">
    <p>
      We invite both short (4 page) and long (8 page) anonymized submissions in the <a href="https://icml.cc">ICML LaTeX format</a> that develop algorithms, benchmarks, and ideas to allow reinforcement learning agents to learn more effectively by making self-supervised predictions about their environment. More concretely, we welcome submissions around, but not necessarily limited to, the following broad questions: 
    </p>
    <p>
          <ul>
              <li>Q1?</li>
              <li>Q2?</li>
          </ul>
      </p>
      <p>We welcome review and positional papers that may foster discussions. 
       Note that as per ICML guidelines, we don't accept works previously published in other conferences on machine learning, but are open to works that are currently under submission to a conference (such as NeurIPS 2024).</p>
      <p>
        The workshop will focus on novel and unpublished work including, but not limited to, the areas of:
        <ul>
          <li>In-context reinforcement learning</li>
          <li>Meta-reinforcement learning</li>
          <li>RL algorithm discovery</li>
          <li>Fairness &amp; interpretability via AutoRL</li>
          <li>Curricula and open-endedness in RL</li>
          <li>AutoML for reinforcement learning</li>
          <li>Reinforcement learning for LLMs</li>
          <li>NAS for deep reinforcement learning</li>
          <li>Theoretical guarantees for AutoRL</li>
          <li>Feature- &amp; Hyperparameter importance for RL algorithms</li>
          <li>Demos of AutoRL systems</li>
          <li>Hyperparameter agnostic RL algorithms</li>
        </ul>

      </p>      
      <p>
        Submissions should be uploaded on OpenReview: <a class="red" href="https://openreview.net/">AutoRL submission link</a>
      </p>
      <p>
        In case of any issues or questions, feel free to email the workshop organizers at: <a href="mailto:autorlworkshop@ai.uni-hannover.de" class="red">autorlworkshop@ai.uni-hannover.de</a>.
      </p>

  </div>
</div>-->


<br />


<hr />

<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2>Speakers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://psc-g.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/pablo.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://psc-g.github.io/">Pablo Samuel Castro</a>
      <h6>DeepMind, Université de Montréal and Mila</h6>
    </div>
  </div>

  <div class="col-xs-6 col-lg-3 people">
    <a href="https://www.michaeldennis.ai/">
      <img class="people-pic" src="{{ "/static/img/people/michael.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.michaeldennis.ai/">Michael Dennis</a>
      <h6>DeepMind</h6>
    </div>
  </div>

  <div class="col-xs-6 col-lg-3 people">
    <a href="https://proceduralia.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/pierluca.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://proceduralia.github.io/">Pierluca D'Oro</a>
      <h6>Mila, Meta</h6>
    </div>
  </div>
  
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://rraileanu.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/roberta.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://rraileanu.github.io/">Roberta Raileanu</a>
      <h6>Meta</h6>
    </div>
  </div>
</div>

  
<div class="row">
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://ai.stanford.edu/~cbfinn/">
      <img class="people-pic" src="{{ "/static/img/people/chelsea.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>
      <h6>Stanford University</h6>
    </div>
  </div>

<!--  <div class="col-xs-6 col-lg-3 people">
    <a href="">
      <img class="people-pic" src="{{ "/static/img/people/blank.jpg" | prepend:site.baseurl }}"> 
    </a>
    <div class="people-name">
      <a href="https://autorlworkshop.github.io/#accepted">Spotlight papers' speakers</a>
      <h6></h6>
    </div>
  </div>-->

<!--  <div class="col-xs-6 col-lg-3 people">    
  </div>-->

<!--  <div class="col-xs-6 col-lg-3 people">
    <a href="https://zhongwen.one/">
      <img class="people-pic" src="{{ "/static/img/people/zhongwen.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://zhongwen.one/">Zhongwen Xu</a>
      <h6>Sea AI Lab</h6>
    </div>
  </div>-->
</div>

<hr />

<!--
#TODO
<div class="row" id="intro">
    <div class="col-xs-12">
        <h2>Introduction</h2>
        <p>AutoRL promises to...</p>. 

        <p> The aims of this workshop are to bring together existing approaches to AutoRL and expand the current capabilities of methods, while also considering new application areas:</p>
        <ul>
        <li>How can we?</li>
        <li>How can we?</li>
        </ul>
    </div>
</div>

<hr />-->


<div class="row" id="panel_discussion">
  <div class="col-xs-12">
    <h2>Panel Discussion</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://psc-g.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/pablo.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://psc-g.github.io/">Pablo Samuel Castro</a>
      <h6>DeepMind, Université de Montréal and Mila</h6>
    </div>
  </div>

  <div class="col-xs-6 col-lg-3 people">
    <a href="https://mila.quebec/en/doina-precup">
      <img class="people-pic" src="{{ "/static/img/people/doina.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://mila.quebec/en/doina-precup">Doina Precup</a>
      <h6>McGill University, DeepMind</h6>
    </div>
  </div>
  
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://www.jakebeck.com/">
      <img class="people-pic" src="{{ "/static/img/people/jacob.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.jakebeck.com/">Jacob Beck</a>
      <h6>University of Oxford</h6>
    </div>
  </div>

  <div class="col-xs-6 col-lg-3 people">
    <a href="https://scholar.google.com/citations?user=wogOjBsAAAAJ&hl=en">
      <img class="people-pic" src="{{ "/static/img/people/alexander.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=wogOjBsAAAAJ&hl=en">Alexander D. Goldie</a>
      <h6>University of Oxford</h6>
    </div>
  </div>

</div>

<hr />


<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://www.ai.uni-hannover.de/de/institut/team/eimer/">
      <img class="people-pic" src="{{ "/static/img/people/theresa.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.ai.uni-hannover.de/de/institut/team/eimer/">Theresa Eimer</a>
      <h6>Leibniz Universität Hannover</h6>
    </div>
  </div>

  <div class="col-xs-6 col-lg-3 people">
    <a href="https://ml.informatik.uni-freiburg.de/people/rajan/index.html">
      <img class="people-pic" src="{{ "/static/img/people/raghu.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://ml.informatik.uni-freiburg.de/people/rajan/index.html">Raghu Rajan</a>
      <h6>University of Freiburg</h6>
    </div>
  </div>

  <div class="col-xs-6 col-lg-3 people">
    <a href="https://andrebiedenkapp.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/andre.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://andrebiedenkapp.github.io/">André Biedenkapp</a>
      <h6>University of Freiburg</h6>
    </div>
  </div>

<!--  <div class="col-xs-6 col-lg-3 people">
  </div>

  <div class="col-xs-6 col-lg-3 people">
  </div>-->

  <div class="col-xs-6 col-lg-3 people">
    <a href="http://vu-nguyen.org/">
      <img class="people-pic" src="{{ "/static/img/people/vu.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name people">
      <a href="http://vu-nguyen.org/">Vu Nguyen</a>
      <h6>Amazon Research</h6>
    </div>
  </div>
  
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://www.afaust.info/">
      <img class="people-pic" src="{{ "/static/img/people/aleksandra.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.afaust.info/">Aleksandra Faust</a>
      <h6>DeepMind</h6>
    </div>
  </div>

  <div class="col-xs-6 col-lg-3 people">
    <a href="https://www.linkedin.com/in/julian-dierkes-b8883820b/">
      <img class="people-pic" src="{{ "/static/img/people/julian.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.linkedin.com/in/julian-dierkes-b8883820b/">Julian Dierkes</a>
      <h6>RWTH Aachen University</h6>
    </div>
  </div>
</div>

<hr />

<div class="row">
    <div class="col-xs-8">
    <img src="/static/img/fig_1_survey.png">
    </div>
</div>

<br/>
<br/>

<div class="row">
  <div class="col-xs-12">
    <h2>Contact</h2>
    <p>
    <a href="mailto:autorlworkshop@ai.uni-hannover.de">autorlworkshop@ai.uni-hannover.de</a>
       </p>
  </div>
</div>
<div class="row">
  <div class="col-md-12">
    <ol>
<!--<li>Finn, Chelsea, Ian Goodfellow, and Sergey Levine. "Unsupervised learning for physical interaction through video prediction." NeurIPS (2016).</li>   
<li>Ha, David, and Jürgen Schmidhuber. "Recurrent world models facilitate policy evolution." NeurIPS (2018). </li>-->

</ol>
  </div>
</div>




<div class="text-center p-3" style="background-color: rgba(0, 0, 0, 0)">
    <h6>Website theme originally inspired from the <a href="https://github.com/vigilworkshop/vigilworkshop.github.io">VIGIL workshop</a>, stolen from the <a href="https://github.com/sslrlworkshop/sslrlworkshop.github.io">SSL-RL workshop</a>. </h6>
  </div>
